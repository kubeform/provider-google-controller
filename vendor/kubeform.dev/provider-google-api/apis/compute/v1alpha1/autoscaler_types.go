/*
Copyright AppsCode Inc. and Contributors

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

// Code generated by Kubeform. DO NOT EDIT.

package v1alpha1

import (
	base "kubeform.dev/apimachinery/api/v1alpha1"

	core "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	kmapi "kmodules.xyz/client-go/api/v1"
	"sigs.k8s.io/cli-utils/pkg/kstatus/status"
)

// +genclient
// +k8s:openapi-gen=true
// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object
// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:printcolumn:name="Phase",type=string,JSONPath=`.status.phase`

type Autoscaler struct {
	metav1.TypeMeta   `json:",inline,omitempty"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	Spec              AutoscalerSpec   `json:"spec,omitempty"`
	Status            AutoscalerStatus `json:"status,omitempty"`
}

type AutoscalerSpecAutoscalingPolicyCpuUtilization struct {
	// Indicates whether predictive autoscaling based on CPU metric is enabled. Valid values are:
	//
	// - NONE (default). No predictive method is used. The autoscaler scales the group to meet current demand based on real-time metrics.
	//
	// - OPTIMIZE_AVAILABILITY. Predictive autoscaling improves availability by monitoring daily and weekly load patterns and scaling out ahead of anticipated demand.
	// +optional
	PredictiveMethod *string `json:"predictiveMethod,omitempty" tf:"predictive_method"`
	// The target CPU utilization that the autoscaler should maintain.
	// Must be a float value in the range (0, 1]. If not specified, the
	// default is 0.6.
	//
	// If the CPU level is below the target utilization, the autoscaler
	// scales down the number of instances until it reaches the minimum
	// number of instances you specified or until the average CPU of
	// your instances reaches the target utilization.
	//
	// If the average CPU is above the target utilization, the autoscaler
	// scales up until it reaches the maximum number of instances you
	// specified or until the average utilization reaches the target
	// utilization.
	Target *float64 `json:"target" tf:"target"`
}

type AutoscalerSpecAutoscalingPolicyLoadBalancingUtilization struct {
	// Fraction of backend capacity utilization (set in HTTP(s) load
	// balancing configuration) that autoscaler should maintain. Must
	// be a positive float value. If not defined, the default is 0.8.
	Target *float64 `json:"target" tf:"target"`
}

type AutoscalerSpecAutoscalingPolicyMetric struct {
	// The identifier (type) of the Stackdriver Monitoring metric.
	// The metric cannot have negative values.
	//
	// The metric must have a value type of INT64 or DOUBLE.
	Name *string `json:"name" tf:"name"`
	// The target value of the metric that autoscaler should
	// maintain. This must be a positive value. A utilization
	// metric scales number of virtual machines handling requests
	// to increase or decrease proportionally to the metric.
	//
	// For example, a good metric to use as a utilizationTarget is
	// www.googleapis.com/compute/instance/network/received_bytes_count.
	// The autoscaler will work to keep this value constant for each
	// of the instances.
	// +optional
	Target *float64 `json:"target,omitempty" tf:"target"`
	// Defines how target utilization value is expressed for a
	// Stackdriver Monitoring metric. Possible values: ["GAUGE", "DELTA_PER_SECOND", "DELTA_PER_MINUTE"]
	// +optional
	Type *string `json:"type,omitempty" tf:"type"`
}

type AutoscalerSpecAutoscalingPolicyScaleInControlMaxScaledInReplicas struct {
	// Specifies a fixed number of VM instances. This must be a positive
	// integer.
	// +optional
	Fixed *int64 `json:"fixed,omitempty" tf:"fixed"`
	// Specifies a percentage of instances between 0 to 100%, inclusive.
	// For example, specify 80 for 80%.
	// +optional
	Percent *int64 `json:"percent,omitempty" tf:"percent"`
}

type AutoscalerSpecAutoscalingPolicyScaleInControl struct {
	// A nested object resource
	// +optional
	MaxScaledInReplicas *AutoscalerSpecAutoscalingPolicyScaleInControlMaxScaledInReplicas `json:"maxScaledInReplicas,omitempty" tf:"max_scaled_in_replicas"`
	// How long back autoscaling should look when computing recommendations
	// to include directives regarding slower scale down, as described above.
	// +optional
	TimeWindowSec *int64 `json:"timeWindowSec,omitempty" tf:"time_window_sec"`
}

type AutoscalerSpecAutoscalingPolicyScalingSchedules struct {
	// A description of a scaling schedule.
	// +optional
	Description *string `json:"description,omitempty" tf:"description"`
	// A boolean value that specifies if a scaling schedule can influence autoscaler recommendations. If set to true, then a scaling schedule has no effect.
	// +optional
	Disabled *bool `json:"disabled,omitempty" tf:"disabled"`
	// The duration of time intervals (in seconds) for which this scaling schedule will be running. The minimum allowed value is 300.
	DurationSec *int64 `json:"durationSec" tf:"duration_sec"`
	// Minimum number of VM instances that autoscaler will recommend in time intervals starting according to schedule.
	MinRequiredReplicas *int64  `json:"minRequiredReplicas" tf:"min_required_replicas"`
	Name                *string `json:"name" tf:"name"`
	// The start timestamps of time intervals when this scaling schedule should provide a scaling signal. This field uses the extended cron format (with an optional year field).
	Schedule *string `json:"schedule" tf:"schedule"`
	// The time zone to be used when interpreting the schedule. The value of this field must be a time zone name from the tz database: http://en.wikipedia.org/wiki/Tz_database.
	// +optional
	TimeZone *string `json:"timeZone,omitempty" tf:"time_zone"`
}

type AutoscalerSpecAutoscalingPolicy struct {
	// The number of seconds that the autoscaler should wait before it
	// starts collecting information from a new instance. This prevents
	// the autoscaler from collecting information when the instance is
	// initializing, during which the collected usage would not be
	// reliable. The default time autoscaler waits is 60 seconds.
	//
	// Virtual machine initialization times might vary because of
	// numerous factors. We recommend that you test how long an
	// instance may take to initialize. To do this, create an instance
	// and time the startup process.
	// +optional
	CooldownPeriod *int64 `json:"cooldownPeriod,omitempty" tf:"cooldown_period"`
	// Defines the CPU utilization policy that allows the autoscaler to
	// scale based on the average CPU utilization of a managed instance
	// group.
	// +optional
	CpuUtilization *AutoscalerSpecAutoscalingPolicyCpuUtilization `json:"cpuUtilization,omitempty" tf:"cpu_utilization"`
	// Configuration parameters of autoscaling based on a load balancer.
	// +optional
	LoadBalancingUtilization *AutoscalerSpecAutoscalingPolicyLoadBalancingUtilization `json:"loadBalancingUtilization,omitempty" tf:"load_balancing_utilization"`
	// The maximum number of instances that the autoscaler can scale up
	// to. This is required when creating or updating an autoscaler. The
	// maximum number of replicas should not be lower than minimal number
	// of replicas.
	MaxReplicas *int64 `json:"maxReplicas" tf:"max_replicas"`
	// Configuration parameters of autoscaling based on a custom metric.
	// +optional
	Metric []AutoscalerSpecAutoscalingPolicyMetric `json:"metric,omitempty" tf:"metric"`
	// The minimum number of replicas that the autoscaler can scale down
	// to. This cannot be less than 0. If not provided, autoscaler will
	// choose a default value depending on maximum number of instances
	// allowed.
	MinReplicas *int64 `json:"minReplicas" tf:"min_replicas"`
	// Defines operating mode for this policy. Default value: "ON" Possible values: ["OFF", "ONLY_UP", "ON"]
	// +optional
	Mode *string `json:"mode,omitempty" tf:"mode"`
	// Defines scale in controls to reduce the risk of response latency
	// and outages due to abrupt scale-in events
	// +optional
	ScaleInControl *AutoscalerSpecAutoscalingPolicyScaleInControl `json:"scaleInControl,omitempty" tf:"scale_in_control"`
	// Scaling schedules defined for an autoscaler. Multiple schedules can be set on an autoscaler and they can overlap.
	// +optional
	ScalingSchedules []AutoscalerSpecAutoscalingPolicyScalingSchedules `json:"scalingSchedules,omitempty" tf:"scaling_schedules"`
}

type AutoscalerSpec struct {
	KubeformOutput *AutoscalerSpecResource `json:"kubeformOutput,omitempty" tf:"-"`

	Resource AutoscalerSpecResource `json:"resource" tf:"resource"`

	UpdatePolicy base.UpdatePolicy `json:"updatePolicy,omitempty" tf:"-"`

	TerminationPolicy base.TerminationPolicy `json:"terminationPolicy,omitempty" tf:"-"`

	ProviderRef core.LocalObjectReference `json:"providerRef" tf:"-"`
}

type AutoscalerSpecResource struct {
	Timeouts *base.ResourceTimeout `json:"timeouts,omitempty" tf:"timeouts"`

	ID string `json:"id,omitempty" tf:"id,omitempty"`

	// The configuration parameters for the autoscaling algorithm. You can
	// define one or more of the policies for an autoscaler: cpuUtilization,
	// customMetricUtilizations, and loadBalancingUtilization.
	//
	// If none of these are specified, the default will be to autoscale based
	// on cpuUtilization to 0.6 or 60%.
	AutoscalingPolicy *AutoscalerSpecAutoscalingPolicy `json:"autoscalingPolicy" tf:"autoscaling_policy"`
	// Creation timestamp in RFC3339 text format.
	// +optional
	CreationTimestamp *string `json:"creationTimestamp,omitempty" tf:"creation_timestamp"`
	// An optional description of this resource.
	// +optional
	Description *string `json:"description,omitempty" tf:"description"`
	// Name of the resource. The name must be 1-63 characters long and match
	// the regular expression '[a-z]([-a-z0-9]*[a-z0-9])?' which means the
	// first character must be a lowercase letter, and all following
	// characters must be a dash, lowercase letter, or digit, except the last
	// character, which cannot be a dash.
	Name *string `json:"name" tf:"name"`
	// +optional
	Project *string `json:"project,omitempty" tf:"project"`
	// +optional
	SelfLink *string `json:"selfLink,omitempty" tf:"self_link"`
	// URL of the managed instance group that this autoscaler will scale.
	Target *string `json:"target" tf:"target"`
	// URL of the zone where the instance group resides.
	// +optional
	Zone *string `json:"zone,omitempty" tf:"zone"`
}

type AutoscalerStatus struct {
	// Resource generation, which is updated on mutation by the API Server.
	// +optional
	ObservedGeneration int64 `json:"observedGeneration,omitempty"`
	// +optional
	Phase status.Status `json:"phase,omitempty"`
	// +optional
	Conditions []kmapi.Condition `json:"conditions,omitempty"`
}

// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object
// +kubebuilder:object:root=true

// AutoscalerList is a list of Autoscalers
type AutoscalerList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	// Items is a list of Autoscaler CRD objects
	Items []Autoscaler `json:"items,omitempty"`
}
